{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 2 example -- LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = pd.Series(range(0,2400))\n",
    "x2 = pd.Series(range(10,10+2400))\n",
    "x3 = pd.Series(range(20,20+2400))\n",
    "y  = pd.Series(range(100,100+2400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'x1':x1,'x2':x2,'x3':x3,'y':y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100   \n",
    "n_steps = 300         \n",
    "n_inputs = 3      \n",
    "n_outputs = 1     \n",
    "trainEpoch = 50 \n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydata():\n",
    "    def __init__(self,data,batch_size,n_steps,n_inputs,n_outputs,y):\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps    = n_steps\n",
    "        self.n_inputs    = n_inputs\n",
    "        self.n_outputs  = n_outputs\n",
    "        self.train_x = data.iloc[0:len(data)-n_steps,0:n_inputs].values.astype(np.float32)\n",
    "        # 0:len(data)-n_step 保留 n_step 數量的資料   #0:n_inputs 使用前幾個變數\n",
    "        self.train_y = data.iloc[0:len(data)-n_steps][y].values.astype(np.float32)\n",
    "        self.test_x = data.iloc[len(data)-n_steps:len(data),0:n_inputs].values.astype(np.float32)\n",
    "        #取出最後 n_step 筆\n",
    "        self.test_y = data.iloc[len(data)-n_steps:len(data)][y].values.astype(np.float32)\n",
    "        #return self.train_x, self.train_y, self.test_x, self.test_y\n",
    "    \n",
    "    def ts_Batch(self):\n",
    "        X_train = []\n",
    "        y_train = [] \n",
    "        for i in range(self.n_steps,len(self.train_x)+1):\n",
    "            X_train.append(np.array(self.train_x[i-self.n_steps:i]).reshape([1,self.n_steps,self.n_inputs]) )\n",
    "            y_train.append(np.array(self.train_y[i-self.n_steps:i]).reshape([1,self.n_steps,self.n_outputs]))\n",
    "        \n",
    "        \n",
    "        if self.batch_size ==1:\n",
    "            totalBatches = len(X_train)\n",
    "            return X_train, y_train, totalBatches\n",
    "        \n",
    "        elif self.batch_size >1 :\n",
    "            LSTM_x = []\n",
    "            LSTM_y = []\n",
    "            for i in range(0,len(X_train),self.batch_size):\n",
    "                LSTM_x.append(np.array(X_train[i:i+self.batch_size]).reshape([-1,self.n_steps,self.n_inputs]).astype(np.float32))\n",
    "                LSTM_y.append(np.array(y_train[i:i+self.batch_size]).reshape([-1,self.n_steps,self.n_outputs]).astype(np.float32))\n",
    "            totalBatches = len(LSTM_x)\n",
    "\n",
    "        return LSTM_x, LSTM_y, totalBatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_MODEL(tf.keras.Model):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_outputs):\n",
    "        super().__init__()\n",
    "        tf.compat.v1.set_random_seed(123)\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps  = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.cell = tf.keras.layers.RNN([tf.keras.layers.LSTMCell(100),tf.keras.layers.LSTMCell(50),tf.keras.layers.LSTMCell(25)], \n",
    "                                        return_sequences=True, return_state=True)\n",
    "        self.dense1 = tf.keras.layers.Dense(units = 10)\n",
    "        self.dense2 = tf.keras.layers.Dense(units = 5)\n",
    "        self.dense3 = tf.keras.layers.Dense(units = n_outputs)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        output ,sequence, state,st= self.cell(inputs)\n",
    "        #print(output)\n",
    "        output = self.dense1(output)\n",
    "        output = self.dense2(output)\n",
    "        output = self.dense3(output)\n",
    "        #print(output)\n",
    "\n",
    "\n",
    "        return output#,sequence, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_MODEL(tf.keras.Model):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_outputs):\n",
    "        super().__init__()\n",
    "        tf.compat.v1.set_random_seed(123)\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps  = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.cell = tf.keras.layers.RNN([tf.keras.layers.LSTMCell(100),tf.keras.layers.LSTMCell(40)], \n",
    "                                        return_sequences=True, return_state=True)\n",
    "        self.dense1 = tf.keras.layers.Dense(units = 10)\n",
    "        self.dense2 = tf.keras.layers.Dense(units = 5)\n",
    "        self.dense3 = tf.keras.layers.Dense(units = n_outputs)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        output ,sequence, state= self.cell(inputs)\n",
    "        #print(output)\n",
    "        output = self.dense1(output)\n",
    "        output = self.dense2(output)\n",
    "        output = self.dense3(output)\n",
    "        #print(output)\n",
    "\n",
    "\n",
    "        return output#,sequence, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = mydata(data,batch_size,n_steps,n_inputs,n_outputs,'y')\n",
    "model = LSTM_MODEL(batch_size, n_steps, n_inputs, n_outputs)\n",
    "#dataloader = MnistLoader()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 4171042.500000\n",
      "epoch 2: loss 4129733.000000\n",
      "epoch 3: loss 4075221.000000\n",
      "epoch 4: loss 4010616.000000\n",
      "epoch 5: loss 3936071.250000\n",
      "epoch 6: loss 3848699.250000\n",
      "epoch 7: loss 3747635.750000\n",
      "epoch 8: loss 3632423.250000\n",
      "epoch 9: loss 3503345.000000\n",
      "epoch 10: loss 3360757.000000\n",
      "epoch 11: loss 3205904.750000\n",
      "epoch 12: loss 3040425.750000\n",
      "epoch 13: loss 2866500.250000\n",
      "epoch 14: loss 2686891.000000\n",
      "epoch 15: loss 2504546.250000\n",
      "epoch 16: loss 2322875.250000\n",
      "epoch 17: loss 2145668.000000\n",
      "epoch 18: loss 2145295.500000\n",
      "epoch 19: loss 1938128.000000\n",
      "epoch 20: loss 1777179.125000\n",
      "epoch 21: loss 1634632.125000\n",
      "epoch 22: loss 1503029.500000\n",
      "epoch 23: loss 1361953.250000\n",
      "epoch 24: loss 1253337.250000\n",
      "epoch 25: loss 1158931.500000\n",
      "epoch 26: loss 1030616.000000\n",
      "epoch 27: loss 991843.812500\n",
      "epoch 28: loss 969896.312500\n",
      "epoch 29: loss 896037.125000\n",
      "epoch 30: loss 826245.562500\n",
      "epoch 31: loss 894608.187500\n",
      "epoch 32: loss 775194.875000\n",
      "epoch 33: loss 753607.687500\n",
      "epoch 34: loss 732778.500000\n",
      "epoch 35: loss 697178.562500\n",
      "epoch 36: loss 616529.687500\n",
      "epoch 37: loss 672083.937500\n",
      "epoch 38: loss 687107.750000\n",
      "epoch 39: loss 599566.312500\n",
      "epoch 40: loss 1820232.750000\n",
      "epoch 41: loss 1658107.125000\n",
      "epoch 42: loss 1531339.250000\n",
      "epoch 43: loss 1493238.875000\n",
      "epoch 44: loss 1329343.625000\n",
      "epoch 45: loss 1181308.875000\n",
      "epoch 46: loss 1078002.125000\n",
      "epoch 47: loss 950323.500000\n",
      "epoch 48: loss 890059.000000\n",
      "epoch 49: loss 858675.375000\n",
      "epoch 50: loss 735086.437500\n",
      "Wall time: 8min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y, num_batch = dataloader.ts_Batch()\n",
    "with tf.device('/GPU:0'):\n",
    "    for j in range(trainEpoch):\n",
    "        for i in range(num_batch):\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(X[i])\n",
    "                loss   = tf.keras.losses.mean_squared_error(y_true = y[i], y_pred = y_pred )\n",
    "                loss   = tf.reduce_mean(loss)\n",
    "            grads  = tape.gradient(loss, model.variables)\n",
    "            optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        print(\"epoch %d: loss %f\" % (j+1, loss.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
